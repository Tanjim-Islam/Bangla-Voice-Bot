{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <span style=\"font-size:50px;\"><b>Speech to Text</b></span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import torchaudio\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000005f3362c</td>\n",
       "      <td>ও বলেছে আপনার ঠিকানা!</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001dddd002</td>\n",
       "      <td>কোন মহান রাষ্ট্রের নাগরিক হতে চাও?</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00001e0bc131</td>\n",
       "      <td>আমি তোমার কষ্টটা বুঝছি, কিন্তু এটা সঠিক পথ না।</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000024b3d810</td>\n",
       "      <td>নাচ শেষ হওয়ার পর সকলে শরীর ধুয়ে একসঙ্গে ভোজন...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000028220ab3</td>\n",
       "      <td>হুমম, ওহ হেই, দেখো।</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           sentence  split\n",
       "0  000005f3362c                              ও বলেছে আপনার ঠিকানা!  train\n",
       "1  00001dddd002                 কোন মহান রাষ্ট্রের নাগরিক হতে চাও?  train\n",
       "2  00001e0bc131     আমি তোমার কষ্টটা বুঝছি, কিন্তু এটা সঠিক পথ না।  train\n",
       "3  000024b3d810  নাচ শেষ হওয়ার পর সকলে শরীর ধুয়ে একসঙ্গে ভোজন...  train\n",
       "4  000028220ab3                                হুমম, ওহ হেই, দেখো।  train"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the paths to the data directories\n",
    "BASE_DIR = 'E:\\Studies\\\\11th Semester\\\\425\\\\Project\\\\Dataset\\\\bengaliai-speech'\n",
    "train_data_dir = f\"{BASE_DIR}/train_mp3s/\"  \n",
    "test_data_dir = f\"{BASE_DIR}/test_mp3s/\" \n",
    "train_csv_path = f\"{BASE_DIR}/train.csv\" \n",
    "domains = f\"{BASE_DIR}/examples/\" \n",
    "\n",
    "path_template = \"E:\\Studies\\\\11th Semester\\\\425\\\\Project\\\\Dataset\\\\bengaliai-speech\\\\train_mp3s\\\\{}.mp3\"\n",
    "\n",
    "# Load the train.csv file using pandas\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Preview the first few rows of the DataFrame\n",
    "display(train_df.head())\n",
    "\n",
    "DOMAINS = os.listdir(f'{BASE_DIR}/examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio data shape: (5,)\n",
      "Transcriptions shape: (5,)\n"
     ]
    }
   ],
   "source": [
    "# Load audio files and corresponding transcriptions\n",
    "audio_data = []  # List to store audio data\n",
    "transcriptions = []  # List to store corresponding transcriptions\n",
    "\n",
    "for idx, row in train_df.head(5).iterrows():\n",
    "    audio_file_path = path_template.format(row['id'])\n",
    "\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    # Append audio data and transcription to lists\n",
    "    audio_data.append(audio)\n",
    "    transcriptions.append(row['sentence'])\n",
    "    \n",
    "audio_data = np.array(audio_data,dtype = 'object')\n",
    "transcriptions = np.array(transcriptions,dtype = 'object')\n",
    "\n",
    "# Check the shapes of the loaded data\n",
    "print(\"Audio data shape:\", audio_data.shape)\n",
    "print(\"Transcriptions shape:\", transcriptions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Summary:\n",
      "Total number of audio files in the training directory: 963636\n",
      "Total number of audio files in the test directory: 3\n",
      "Total number of samples in the training data: 963636\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of audio files in the training and test directories\n",
    "train_audio_files = os.listdir(train_data_dir)\n",
    "test_audio_files = os.listdir(test_data_dir)\n",
    "\n",
    "# Get the total duration of audio data in the training set (in seconds)\n",
    "train_total_duration = 0\n",
    "SAMPLES_TAKEN = 10000\n",
    "for idx, row in train_df.head(SAMPLES_TAKEN).iterrows():\n",
    "    audio_file_path = path_template.format(row['id'])\n",
    "\n",
    "test_duration = 0\n",
    "for test_file in test_audio_files:\n",
    "    audio_file_path = os.path.join(test_data_dir, str(test_file))\n",
    "    \n",
    "# Get the total number of samples in the training data\n",
    "total_samples = train_df.shape[0]\n",
    "\n",
    "# Print the data summary\n",
    "print(\"Data Summary:\")\n",
    "print(f\"Total number of audio files in the training directory: {len(train_audio_files)}\")\n",
    "print(f\"Total number of audio files in the test directory: {len(test_audio_files)}\")\n",
    "print(f\"Total number of samples in the training data: {total_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Listen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = [0, 10, 20, 30, 40]\n",
    "\n",
    "for idx in random_indices:\n",
    "    row = train_df.iloc[idx]\n",
    "    audio_file_path = path_template.format(row['id'])\n",
    "\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    # Print the transcription and play the audio\n",
    "    print(\"Transcription:\", row['sentence'])\n",
    "    ipd.display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_file in test_audio_files:\n",
    "    audio_file_path = os.path.join(test_data_dir, str(test_file))\n",
    "    \n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "    ipd.display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "domain_counts = train_df['split'].value_counts()\n",
    "\n",
    "# Plot the data distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "domain_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Data Distribution Across Domains\")\n",
    "plt.xlabel(\"Domain\")\n",
    "plt.ylabel(\"Number of Recordings\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in random_indices:\n",
    "    row = train_df.iloc[idx]\n",
    "    audio_file_path = os.path.join(train_data_dir, f\"{row['id']}.mp3\")\n",
    "\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(audio)\n",
    "    plt.title(f\"Waveform - Audio File ID: {row['id']}\")\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the log Mel spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Log Mel Spectrogram - Audio File ID: {row['id']}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Mel Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 5 transcriptions\n",
    "transcriptions = train_df['sentence'][:5].tolist()\n",
    "\n",
    "# Convert transcriptions to lowercase\n",
    "transcriptions_lower = [transcription.lower() for transcription in transcriptions]\n",
    "\n",
    "# Remove punctuation\n",
    "translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "transcriptions_no_punct = [transcription.translate(translator) for transcription in transcriptions_lower]\n",
    "\n",
    "# Tokenization\n",
    "nltk.download('punkt')  \n",
    "transcriptions_tokens = [word_tokenize(transcription) for transcription in transcriptions_no_punct]\n",
    "\n",
    "\n",
    "nltk.download('stopwords')  \n",
    "stop_words = set(stopwords.words('bengali'))\n",
    "transcriptions_no_stopwords = [\n",
    "    [word for word in tokens if word not in stop_words]\n",
    "    for tokens in transcriptions_tokens\n",
    "]\n",
    "\n",
    "nltk.download('wordnet')  \n",
    "stemmer = PorterStemmer()\n",
    "transcriptions_stemmed = [\n",
    "    [stemmer.stem(word) for word in tokens]\n",
    "    for tokens in transcriptions_no_stopwords\n",
    "]\n",
    "\n",
    "# Print the preprocessed transcriptions\n",
    "for i, transcription in enumerate(transcriptions_stemmed):\n",
    "    print(f\"Preprocessed transcription {i+1}: {' '.join(transcription)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 100 transcriptions \n",
    "transcriptions = train_df['sentence'].tolist()\n",
    "\n",
    "# Tokenization\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer\n",
    "transcriptions_tokens = [word_tokenize(transcription) for transcription in transcriptions]\n",
    "\n",
    "# Print the tokenized transcriptions\n",
    "for i, transcription_tokens in enumerate(transcriptions_tokens):\n",
    "    if i%100000 == 0:\n",
    "        print(f\"Tokenized transcription {i+1}: {transcription_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vocab Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 204457\n"
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "vocabulary = set()\n",
    "for transcription_tokens in transcriptions_tokens:\n",
    "    vocabulary.update(transcription_tokens)\n",
    "\n",
    "# print(\"Vocabulary:\")\n",
    "# print(vocabulary)\n",
    "print(f\"Vocabulary Size: {len(vocabulary)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sentence Length Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.46812e+05, 3.01428e+05, 2.76002e+05, 1.89254e+05, 3.83470e+04,\n",
       "        1.00420e+04, 1.62200e+03, 1.13000e+02, 1.10000e+01, 5.00000e+00]),\n",
       " array([  2. ,  25.1,  48.2,  71.3,  94.4, 117.5, 140.6, 163.7, 186.8,\n",
       "        209.9, 233. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAs/ElEQVR4nO3dfXAUdZ7H8U8SyCQ8zMQAyZAjQBRXyPJ0BhhmfbjlyGXAaMkaqwApN2KUggvUQlQedtmA3lbFxdpTPBBqzyrDVokCVQeeiYTNBgnlMoIEczwoKfHwohcmiWAyECEJSd8fVvoYYYFgwkh+71dVV2X6953ffLvbJB873U2EZVmWAAAADBQZ7gYAAADChSAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADBWr3A38GPW3t6umpoa9e/fXxEREeFuBwAAXAfLsnT27FklJSUpMvLq53wIQldRU1Oj5OTkcLcBAABuwJdffqkhQ4ZctYYgdBX9+/eX9N2OdDqdYe4GAABcj2AwqOTkZPv3+NUQhK6i489hTqeTIAQAwC3mei5r4WJpAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIzVqSC0YcMGjR071v5HSL1er3bu3GmPX7hwQbm5uRowYID69eunrKws1dbWhsxRXV2tzMxM9enTRwkJCXruued08eLFkJo9e/bo7rvvlsPh0IgRI1RYWHhZL+vXr9fw4cMVExMjj8ejAwcOhIxfTy8AAMBsnQpCQ4YM0YsvvqiKigodPHhQ//iP/6iHH35Yx44dkyQtWbJE7777rrZt26by8nLV1NTokUcesd/f1tamzMxMtbS0aN++fdq0aZMKCwuVn59v15w8eVKZmZmaMmWKKisrtXjxYj311FPatWuXXbNlyxbl5eVp1apVOnTokMaNGyefz6e6ujq75lq9AAAARFiWZf2QCeLj4/XSSy/p0Ucf1aBBg7R582Y9+uijkqTjx49r1KhR8vv9mjx5snbu3KkHH3xQNTU1SkxMlCRt3LhRy5YtU319vaKjo7Vs2TIVFxfr6NGj9mfMmjVLDQ0NKikpkSR5PB5NnDhR69atkyS1t7crOTlZixYt0vLly9XY2HjNXq5HMBiUy+VSY2OjnE7nD9lNPcbw5cXhbqHTvngxM9wtAABuos78/r7ha4Ta2tr09ttvq6mpSV6vVxUVFWptbVV6erpdM3LkSA0dOlR+v1+S5Pf7NWbMGDsESZLP51MwGLTPKvn9/pA5Omo65mhpaVFFRUVITWRkpNLT0+2a6+nlSpqbmxUMBkMWAADQc3U6CB05ckT9+vWTw+HQ/PnztX37dqWmpioQCCg6OlpxcXEh9YmJiQoEApKkQCAQEoI6xjvGrlYTDAZ1/vx5ff3112pra7tizaVzXKuXKykoKJDL5bKX5OTk69spAADgltTpIHTXXXepsrJS+/fv14IFC5Sdna1PPvmkO3q76VasWKHGxkZ7+fLLL8PdEgAA6Ea9OvuG6OhojRgxQpKUlpamjz76SGvXrtXMmTPV0tKihoaGkDMxtbW1crvdkiS3233Z3V0dd3JdWvP9u7tqa2vldDoVGxurqKgoRUVFXbHm0jmu1cuVOBwOORyOTuwNAABwK/vBzxFqb29Xc3Oz0tLS1Lt3b5WVldljVVVVqq6ultfrlSR5vV4dOXIk5O6u0tJSOZ1Opaam2jWXztFR0zFHdHS00tLSQmra29tVVlZm11xPLwAAAJ06I7RixQpNnz5dQ4cO1dmzZ7V582bt2bNHu3btksvlUk5OjvLy8hQfHy+n06lFixbJ6/Xad2llZGQoNTVVjz/+uNasWaNAIKCVK1cqNzfXPhMzf/58rVu3TkuXLtWTTz6p3bt3a+vWrSou/v+7lfLy8pSdna0JEyZo0qRJeuWVV9TU1KS5c+dK0nX1AgAA0KkgVFdXp1/+8pc6deqUXC6Xxo4dq127dumf/umfJEkvv/yyIiMjlZWVpebmZvl8Pr322mv2+6OiolRUVKQFCxbI6/Wqb9++ys7O1gsvvGDXpKSkqLi4WEuWLNHatWs1ZMgQvf766/L5fHbNzJkzVV9fr/z8fAUCAY0fP14lJSUhF1BfqxcAAIAf/ByhnoznCF2O5wgBAH7sbspzhAAAAG51BCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACM1SvcDQDdbfjy4nC30GlfvJgZ7hYAwAicEQIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMbqVBAqKCjQxIkT1b9/fyUkJGjGjBmqqqoKqfn5z3+uiIiIkGX+/PkhNdXV1crMzFSfPn2UkJCg5557ThcvXgyp2bNnj+6++245HA6NGDFChYWFl/Wzfv16DR8+XDExMfJ4PDpw4EDI+IULF5Sbm6sBAwaoX79+ysrKUm1tbWc2GQAA9GCdCkLl5eXKzc3Vhx9+qNLSUrW2tiojI0NNTU0hdU8//bROnTplL2vWrLHH2tralJmZqZaWFu3bt0+bNm1SYWGh8vPz7ZqTJ08qMzNTU6ZMUWVlpRYvXqynnnpKu3btsmu2bNmivLw8rVq1SocOHdK4cePk8/lUV1dn1yxZskTvvvuutm3bpvLyctXU1OiRRx7p9E4CAAA9U4RlWdaNvrm+vl4JCQkqLy/X/fffL+m7M0Ljx4/XK6+8csX37Ny5Uw8++KBqamqUmJgoSdq4caOWLVum+vp6RUdHa9myZSouLtbRo0ft982aNUsNDQ0qKSmRJHk8Hk2cOFHr1q2TJLW3tys5OVmLFi3S8uXL1djYqEGDBmnz5s169NFHJUnHjx/XqFGj5Pf7NXny5GtuXzAYlMvlUmNjo5xO543uph5l+PLicLdghC9ezAx3CwBwy+rM7+8fdI1QY2OjJCk+Pj5k/ZtvvqmBAwdq9OjRWrFihb799lt7zO/3a8yYMXYIkiSfz6dgMKhjx47ZNenp6SFz+nw++f1+SVJLS4sqKipCaiIjI5Wenm7XVFRUqLW1NaRm5MiRGjp0qF3zfc3NzQoGgyELAADouXrd6Bvb29u1ePFi3XPPPRo9erS9/rHHHtOwYcOUlJSkw4cPa9myZaqqqtJ//Md/SJICgUBICJJkvw4EAletCQaDOn/+vL755hu1tbVdseb48eP2HNHR0YqLi7uspuNzvq+goEDPP/98J/cEAAC4Vd1wEMrNzdXRo0f1wQcfhKyfN2+e/fWYMWM0ePBgTZ06VZ9//rnuuOOOG+/0JlixYoXy8vLs18FgUMnJyWHsCAAAdKcb+tPYwoULVVRUpPfff19Dhgy5aq3H45EknThxQpLkdrsvu3Or47Xb7b5qjdPpVGxsrAYOHKioqKgr1lw6R0tLixoaGv5mzfc5HA45nc6QBQAA9FydCkKWZWnhwoXavn27du/erZSUlGu+p7KyUpI0ePBgSZLX69WRI0dC7u4qLS2V0+lUamqqXVNWVhYyT2lpqbxeryQpOjpaaWlpITXt7e0qKyuza9LS0tS7d++QmqqqKlVXV9s1AADAbJ3601hubq42b96sd955R/3797evtXG5XIqNjdXnn3+uzZs364EHHtCAAQN0+PBhLVmyRPfff7/Gjh0rScrIyFBqaqoef/xxrVmzRoFAQCtXrlRubq4cDockaf78+Vq3bp2WLl2qJ598Urt379bWrVtVXPz/dyzl5eUpOztbEyZM0KRJk/TKK6+oqalJc+fOtXvKyclRXl6e4uPj5XQ6tWjRInm93uu6YwwAAPR8nQpCGzZskPTdLfKXeuONN/TEE08oOjpaf/nLX+xQkpycrKysLK1cudKujYqKUlFRkRYsWCCv16u+ffsqOztbL7zwgl2TkpKi4uJiLVmyRGvXrtWQIUP0+uuvy+fz2TUzZ85UfX298vPzFQgENH78eJWUlIRcQP3yyy8rMjJSWVlZam5uls/n02uvvdapHQQAAHquH/QcoZ6O5whdjucI3Rw8RwgAbtxNe44QAADArYwgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMFanglBBQYEmTpyo/v37KyEhQTNmzFBVVVVIzYULF5Sbm6sBAwaoX79+ysrKUm1tbUhNdXW1MjMz1adPHyUkJOi5557TxYsXQ2r27Nmju+++Ww6HQyNGjFBhYeFl/axfv17Dhw9XTEyMPB6PDhw40OleAACAuToVhMrLy5Wbm6sPP/xQpaWlam1tVUZGhpqamuyaJUuW6N1339W2bdtUXl6umpoaPfLII/Z4W1ubMjMz1dLSon379mnTpk0qLCxUfn6+XXPy5EllZmZqypQpqqys1OLFi/XUU09p165dds2WLVuUl5enVatW6dChQxo3bpx8Pp/q6uquuxcAAGC2CMuyrBt9c319vRISElReXq77779fjY2NGjRokDZv3qxHH31UknT8+HGNGjVKfr9fkydP1s6dO/Xggw+qpqZGiYmJkqSNGzdq2bJlqq+vV3R0tJYtW6bi4mIdPXrU/qxZs2apoaFBJSUlkiSPx6OJEydq3bp1kqT29nYlJydr0aJFWr58+XX1ci3BYFAul0uNjY1yOp03upt6lOHLi8PdghG+eDEz3C0AwC2rM7+/f9A1Qo2NjZKk+Ph4SVJFRYVaW1uVnp5u14wcOVJDhw6V3++XJPn9fo0ZM8YOQZLk8/kUDAZ17Ngxu+bSOTpqOuZoaWlRRUVFSE1kZKTS09Ptmuvp5fuam5sVDAZDFgAA0HPdcBBqb2/X4sWLdc8992j06NGSpEAgoOjoaMXFxYXUJiYmKhAI2DWXhqCO8Y6xq9UEg0GdP39eX3/9tdra2q5Yc+kc1+rl+woKCuRyuewlOTn5OvcGAAC4Fd1wEMrNzdXRo0f19ttvd2U/YbVixQo1Njbay5dffhnulgAAQDfqdSNvWrhwoYqKirR3714NGTLEXu92u9XS0qKGhoaQMzG1tbVyu912zffv7uq4k+vSmu/f3VVbWyun06nY2FhFRUUpKirqijWXznGtXr7P4XDI4XB0Yk8AAIBbWafOCFmWpYULF2r79u3avXu3UlJSQsbT0tLUu3dvlZWV2euqqqpUXV0tr9crSfJ6vTpy5EjI3V2lpaVyOp1KTU21ay6do6OmY47o6GilpaWF1LS3t6usrMyuuZ5eAACA2Tp1Rig3N1ebN2/WO++8o/79+9vX2rhcLsXGxsrlciknJ0d5eXmKj4+X0+nUokWL5PV67bu0MjIylJqaqscff1xr1qxRIBDQypUrlZuba5+NmT9/vtatW6elS5fqySef1O7du7V161YVF///HUt5eXnKzs7WhAkTNGnSJL3yyitqamrS3Llz7Z6u1QsAADBbp4LQhg0bJEk///nPQ9a/8cYbeuKJJyRJL7/8siIjI5WVlaXm5mb5fD699tprdm1UVJSKioq0YMECeb1e9e3bV9nZ2XrhhRfsmpSUFBUXF2vJkiVau3athgwZotdff10+n8+umTlzpurr65Wfn69AIKDx48erpKQk5ALqa/UCAADM9oOeI9TT8Ryhy/EcoZuD5wgBwI27ac8RAgAAuJURhAAAgLEIQgAAwFgEIQAAYCyCEAAAMNYNPVkaQPe6Fe/O4043ALcizggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAY3U6CO3du1cPPfSQkpKSFBERoR07doSMP/HEE4qIiAhZpk2bFlJz5swZzZkzR06nU3FxccrJydG5c+dCag4fPqz77rtPMTExSk5O1po1ay7rZdu2bRo5cqRiYmI0ZswYvffeeyHjlmUpPz9fgwcPVmxsrNLT0/XZZ591dpMBAEAP1ekg1NTUpHHjxmn9+vV/s2batGk6deqUvbz11lsh43PmzNGxY8dUWlqqoqIi7d27V/PmzbPHg8GgMjIyNGzYMFVUVOill17S6tWr9cc//tGu2bdvn2bPnq2cnBx9/PHHmjFjhmbMmKGjR4/aNWvWrNGrr76qjRs3av/+/erbt698Pp8uXLjQ2c0GAAA9UIRlWdYNvzkiQtu3b9eMGTPsdU888YQaGhouO1PU4dNPP1Vqaqo++ugjTZgwQZJUUlKiBx54QF999ZWSkpK0YcMG/eY3v1EgEFB0dLQkafny5dqxY4eOHz8uSZo5c6aamppUVFRkzz158mSNHz9eGzdulGVZSkpK0jPPPKNnn31WktTY2KjExEQVFhZq1qxZ19y+YDAol8ulxsZGOZ3OG9lFPc7w5cXhbgE/Ul+8mBnuFgBAUud+f3fLNUJ79uxRQkKC7rrrLi1YsECnT5+2x/x+v+Li4uwQJEnp6emKjIzU/v377Zr777/fDkGS5PP5VFVVpW+++cauSU9PD/lcn88nv98vSTp58qQCgUBIjcvlksfjsWu+r7m5WcFgMGQBAAA9V5cHoWnTpulPf/qTysrK9Pvf/17l5eWaPn262traJEmBQEAJCQkh7+nVq5fi4+MVCATsmsTExJCajtfXqrl0/NL3Xanm+woKCuRyuewlOTm509sPAABuHb26esJL/+Q0ZswYjR07VnfccYf27NmjqVOndvXHdakVK1YoLy/Pfh0MBglDAAD0YN1++/ztt9+ugQMH6sSJE5Ikt9uturq6kJqLFy/qzJkzcrvddk1tbW1ITcfra9VcOn7p+65U830Oh0NOpzNkAQAAPVe3B6GvvvpKp0+f1uDBgyVJXq9XDQ0NqqiosGt2796t9vZ2eTweu2bv3r1qbW21a0pLS3XXXXfptttus2vKyspCPqu0tFRer1eSlJKSIrfbHVITDAa1f/9+uwYAAJit038aO3funH12R/ruouTKykrFx8crPj5ezz//vLKysuR2u/X5559r6dKlGjFihHw+nyRp1KhRmjZtmp5++mlt3LhRra2tWrhwoWbNmqWkpCRJ0mOPPabnn39eOTk5WrZsmY4ePaq1a9fq5Zdftj/3V7/6lf7hH/5Bf/jDH5SZmam3335bBw8etG+xj4iI0OLFi/W73/1Od955p1JSUvTb3/5WSUlJIXe5hRN3YAEAEF6dDkIHDx7UlClT7Ncd19RkZ2drw4YNOnz4sDZt2qSGhgYlJSUpIyND//Iv/yKHw2G/580339TChQs1depURUZGKisrS6+++qo97nK59Oc//1m5ublKS0vTwIEDlZ+fH/KsoZ/97GfavHmzVq5cqV//+te68847tWPHDo0ePdquWbp0qZqamjRv3jw1NDTo3nvvVUlJiWJiYjq72QAAoAf6Qc8R6um6+zlCnBFCT8JzhAD8WIT9OUIAAAC3AoIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsTodhPbu3auHHnpISUlJioiI0I4dO0LGLctSfn6+Bg8erNjYWKWnp+uzzz4LqTlz5ozmzJkjp9OpuLg45eTk6Ny5cyE1hw8f1n333aeYmBglJydrzZo1l/Wybds2jRw5UjExMRozZozee++9TvcCAADM1ekg1NTUpHHjxmn9+vVXHF+zZo1effVVbdy4Ufv371ffvn3l8/l04cIFu2bOnDk6duyYSktLVVRUpL1792revHn2eDAYVEZGhoYNG6aKigq99NJLWr16tf74xz/aNfv27dPs2bOVk5Ojjz/+WDNmzNCMGTN09OjRTvUCAADMFWFZlnXDb46I0Pbt2zVjxgxJ352BSUpK0jPPPKNnn31WktTY2KjExEQVFhZq1qxZ+vTTT5WamqqPPvpIEyZMkCSVlJTogQce0FdffaWkpCRt2LBBv/nNbxQIBBQdHS1JWr58uXbs2KHjx49LkmbOnKmmpiYVFRXZ/UyePFnjx4/Xxo0br6uXawkGg3K5XGpsbJTT6bzR3fQ3DV9e3OVzAuHyxYuZ4W4BACR17vd3l14jdPLkSQUCAaWnp9vrXC6XPB6P/H6/JMnv9ysuLs4OQZKUnp6uyMhI7d+/3665//777RAkST6fT1VVVfrmm2/smks/p6Om43OupxcAAGC2Xl05WSAQkCQlJiaGrE9MTLTHAoGAEhISQpvo1Uvx8fEhNSkpKZfN0TF22223KRAIXPNzrtXL9zU3N6u5udl+HQwGr7HFAADgVsZdY5coKCiQy+Wyl+Tk5HC3BAAAulGXBiG32y1Jqq2tDVlfW1trj7ndbtXV1YWMX7x4UWfOnAmpudIcl37G36q5dPxavXzfihUr1NjYaC9ffvnldWw1AAC4VXVpEEpJSZHb7VZZWZm9LhgMav/+/fJ6vZIkr9erhoYGVVRU2DW7d+9We3u7PB6PXbN37161trbaNaWlpbrrrrt022232TWXfk5HTcfnXE8v3+dwOOR0OkMWAADQc3U6CJ07d06VlZWqrKyU9N1FyZWVlaqurlZERIQWL16s3/3ud/rP//xPHTlyRL/85S+VlJRk31k2atQoTZs2TU8//bQOHDigv/71r1q4cKFmzZqlpKQkSdJjjz2m6Oho5eTk6NixY9qyZYvWrl2rvLw8u49f/epXKikp0R/+8AcdP35cq1ev1sGDB7Vw4UJJuq5eAACA2Tp9sfTBgwc1ZcoU+3VHOMnOzlZhYaGWLl2qpqYmzZs3Tw0NDbr33ntVUlKimJgY+z1vvvmmFi5cqKlTpyoyMlJZWVl69dVX7XGXy6U///nPys3NVVpamgYOHKj8/PyQZw397Gc/0+bNm7Vy5Ur9+te/1p133qkdO3Zo9OjRds319AIAAMz1g54j1NPxHCHg+vEcIQA/FmF7jhAAAMCthCAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwVpcHodWrVysiIiJkGTlypD1+4cIF5ebmasCAAerXr5+ysrJUW1sbMkd1dbUyMzPVp08fJSQk6LnnntPFixdDavbs2aO7775bDodDI0aMUGFh4WW9rF+/XsOHD1dMTIw8Ho8OHDjQ1ZsLAABuYd1yRuinP/2pTp06ZS8ffPCBPbZkyRK9++672rZtm8rLy1VTU6NHHnnEHm9ra1NmZqZaWlq0b98+bdq0SYWFhcrPz7drTp48qczMTE2ZMkWVlZVavHixnnrqKe3atcuu2bJli/Ly8rRq1SodOnRI48aNk8/nU11dXXdsMgAAuAVFWJZldeWEq1ev1o4dO1RZWXnZWGNjowYNGqTNmzfr0UcflSQdP35co0aNkt/v1+TJk7Vz5049+OCDqqmpUWJioiRp48aNWrZsmerr6xUdHa1ly5apuLhYR48eteeeNWuWGhoaVFJSIknyeDyaOHGi1q1bJ0lqb29XcnKyFi1apOXLl1/XtgSDQblcLjU2NsrpdP6Q3XJFw5cXd/mcQLh88WJmuFsAAEmd+/3dLWeEPvvsMyUlJen222/XnDlzVF1dLUmqqKhQa2ur0tPT7dqRI0dq6NCh8vv9kiS/368xY8bYIUiSfD6fgsGgjh07ZtdcOkdHTcccLS0tqqioCKmJjIxUenq6XXMlzc3NCgaDIQsAAOi5ujwIeTweFRYWqqSkRBs2bNDJkyd133336ezZswoEAoqOjlZcXFzIexITExUIBCRJgUAgJAR1jHeMXa0mGAzq/Pnz+vrrr9XW1nbFmo45rqSgoEAul8tekpOTb2gfAACAW0Ovrp5w+vTp9tdjx46Vx+PRsGHDtHXrVsXGxnb1x3WpFStWKC8vz34dDAYJQwAA9GDdfvt8XFycfvKTn+jEiRNyu91qaWlRQ0NDSE1tba3cbrckye12X3YXWcfra9U4nU7FxsZq4MCBioqKumJNxxxX4nA45HQ6QxYAANBzdXsQOnfunD7//HMNHjxYaWlp6t27t8rKyuzxqqoqVVdXy+v1SpK8Xq+OHDkScndXaWmpnE6nUlNT7ZpL5+io6ZgjOjpaaWlpITXt7e0qKyuzawAAALo8CD377LMqLy/XF198oX379ukXv/iFoqKiNHv2bLlcLuXk5CgvL0/vv/++KioqNHfuXHm9Xk2ePFmSlJGRodTUVD3++OP6r//6L+3atUsrV65Ubm6uHA6HJGn+/Pn67//+by1dulTHjx/Xa6+9pq1bt2rJkiV2H3l5efr3f/93bdq0SZ9++qkWLFigpqYmzZ07t6s3GQAA3KK6/Bqhr776SrNnz9bp06c1aNAg3Xvvvfrwww81aNAgSdLLL7+syMhIZWVlqbm5WT6fT6+99pr9/qioKBUVFWnBggXyer3q27evsrOz9cILL9g1KSkpKi4u1pIlS7R27VoNGTJEr7/+unw+n10zc+ZM1dfXKz8/X4FAQOPHj1dJScllF1ADAABzdflzhHoSniMEXD+eIwTgxyLszxECAAC4FRCEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYq8ufIwTATLfi4yC45R8AZ4QAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLF6hbsBAAiX4cuLw91Cp33xYma4WwB6FM4IAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYy4ggtH79eg0fPlwxMTHyeDw6cOBAuFsCAAA/Aj0+CG3ZskV5eXlatWqVDh06pHHjxsnn86muri7crQEAgDCLsCzLCncT3cnj8WjixIlat26dJKm9vV3JyclatGiRli9fftX3BoNBuVwuNTY2yul0dnlvt+LD3ADgRvAgSNxMnfn93aOfLN3S0qKKigqtWLHCXhcZGan09HT5/f7L6pubm9Xc3Gy/bmxslPTdDu0O7c3fdsu8APBj010/R4Er6fjv7XrO9fToIPT111+rra1NiYmJIesTExN1/Pjxy+oLCgr0/PPPX7Y+OTm523oEABO4Xgl3BzDR2bNn5XK5rlrTo4NQZ61YsUJ5eXn26/b2dp05c0YDBgxQRETED5o7GAwqOTlZX375Zbf8mQ3Xh+MQfhyDHweOQ/hxDLqPZVk6e/askpKSrlnbo4PQwIEDFRUVpdra2pD1tbW1crvdl9U7HA45HI6QdXFxcV3ak9Pp5D/4HwGOQ/hxDH4cOA7hxzHoHtc6E9ShR981Fh0drbS0NJWVldnr2tvbVVZWJq/XG8bOAADAj0GPPiMkSXl5ecrOztaECRM0adIkvfLKK2pqatLcuXPD3RoAAAizHh+EZs6cqfr6euXn5ysQCGj8+PEqKSm57ALq7uZwOLRq1arL/vSGm4vjEH4cgx8HjkP4cQx+HHr8c4QAAAD+lh59jRAAAMDVEIQAAICxCEIAAMBYBCEAAGAsgtBNsH79eg0fPlwxMTHyeDw6cOBAuFvq0VavXq2IiIiQZeTIkfb4hQsXlJubqwEDBqhfv37Kysq67KGb6Ly9e/fqoYceUlJSkiIiIrRjx46QccuylJ+fr8GDBys2Nlbp6en67LPPQmrOnDmjOXPmyOl0Ki4uTjk5OTp37txN3Ipb27WOwRNPPHHZ98a0adNCajgGP0xBQYEmTpyo/v37KyEhQTNmzFBVVVVIzfX8DKqurlZmZqb69OmjhIQEPffcc7p48eLN3BRjEIS62ZYtW5SXl6dVq1bp0KFDGjdunHw+n+rq6sLdWo/205/+VKdOnbKXDz74wB5bsmSJ3n33XW3btk3l5eWqqanRI488EsZue4ampiaNGzdO69evv+L4mjVr9Oqrr2rjxo3av3+/+vbtK5/PpwsXLtg1c+bM0bFjx1RaWqqioiLt3btX8+bNu1mbcMu71jGQpGnTpoV8b7z11lsh4xyDH6a8vFy5ubn68MMPVVpaqtbWVmVkZKipqcmuudbPoLa2NmVmZqqlpUX79u3Tpk2bVFhYqPz8/HBsUs9noVtNmjTJys3NtV+3tbVZSUlJVkFBQRi76tlWrVpljRs37opjDQ0NVu/eva1t27bZ6z799FNLkuX3+29Shz2fJGv79u326/b2dsvtdlsvvfSSva6hocFyOBzWW2+9ZVmWZX3yySeWJOujjz6ya3bu3GlFRERY//u//3vTeu8pvn8MLMuysrOzrYcffvhvvodj0PXq6uosSVZ5ebllWdf3M+i9996zIiMjrUAgYNds2LDBcjqdVnNz883dAANwRqgbtbS0qKKiQunp6fa6yMhIpaeny+/3h7Gznu+zzz5TUlKSbr/9ds2ZM0fV1dWSpIqKCrW2toYck5EjR2ro0KEck2508uRJBQKBkP3ucrnk8Xjs/e73+xUXF6cJEybYNenp6YqMjNT+/ftves891Z49e5SQkKC77rpLCxYs0OnTp+0xjkHXa2xslCTFx8dLur6fQX6/X2PGjAl58K/P51MwGNSxY8duYvdmIAh1o6+//lptbW2XPcU6MTFRgUAgTF31fB6PR4WFhSopKdGGDRt08uRJ3XfffTp79qwCgYCio6Mv+8d0OSbdq2PfXu17IRAIKCEhIWS8V69eio+P59h0kWnTpulPf/qTysrK9Pvf/17l5eWaPn262traJHEMulp7e7sWL16se+65R6NHj5ak6/oZFAgErvi90jGGrtXj/4kNmGf69On212PHjpXH49GwYcO0detWxcbGhrEzILxmzZplfz1mzBiNHTtWd9xxh/bs2aOpU6eGsbOeKTc3V0ePHg25RhE/PpwR6kYDBw5UVFTUZXcD1NbWyu12h6kr88TFxeknP/mJTpw4IbfbrZaWFjU0NITUcEy6V8e+vdr3gtvtvuwmgosXL+rMmTMcm25y++23a+DAgTpx4oQkjkFXWrhwoYqKivT+++9ryJAh9vrr+Rnkdruv+L3SMYauRRDqRtHR0UpLS1NZWZm9rr29XWVlZfJ6vWHszCznzp3T559/rsGDBystLU29e/cOOSZVVVWqrq7mmHSjlJQUud3ukP0eDAa1f/9+e797vV41NDSooqLCrtm9e7fa29vl8Xhues8m+Oqrr3T69GkNHjxYEsegK1iWpYULF2r79u3avXu3UlJSQsav52eQ1+vVkSNHQkJpaWmpnE6nUlNTb86GmCTcV2v3dG+//bblcDiswsJC65NPPrHmzZtnxcXFhdwNgK71zDPPWHv27LFOnjxp/fWvf7XS09OtgQMHWnV1dZZlWdb8+fOtoUOHWrt377YOHjxoeb1ey+v1hrnrW9/Zs2etjz/+2Pr4448tSda//uu/Wh9//LH1P//zP5ZlWdaLL75oxcXFWe+88451+PBh6+GHH7ZSUlKs8+fP23NMmzbN+vu//3tr//791gcffGDdeeed1uzZs8O1Sbecqx2Ds2fPWs8++6zl9/utkydPWn/5y1+su+++27rzzjutCxcu2HNwDH6YBQsWWC6Xy9qzZ4916tQpe/n222/tmmv9DLp48aI1evRoKyMjw6qsrLRKSkqsQYMGWStWrAjHJvV4BKGb4N/+7d+soUOHWtHR0dakSZOsDz/8MNwt9WgzZ860Bg8ebEVHR1t/93d/Z82cOdM6ceKEPX7+/Hnrn//5n63bbrvN6tOnj/WLX/zCOnXqVBg77hnef/99S9JlS3Z2tmVZ391C/9vf/tZKTEy0HA6HNXXqVKuqqipkjtOnT1uzZ8+2+vXrZzmdTmvu3LnW2bNnw7A1t6arHYNvv/3WysjIsAYNGmT17t3bGjZsmPX0009f9j9lHIMf5kr7X5L1xhtv2DXX8zPoiy++sKZPn27FxsZaAwcOtJ555hmrtbX1Jm+NGSIsy7Ju9lkoAACAHwOuEQIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWP8HtV1f67GlLVoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = train_df.sentence.apply(lambda x: len(x))\n",
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute descriptive statistics\n",
    "sentence_lengths = [len(tokens) for tokens in transcriptions_tokens]\n",
    "min_length = min(sentence_lengths)\n",
    "max_length = max(sentence_lengths)\n",
    "mean_length = sum(sentence_lengths) / len(sentence_lengths)\n",
    "median_length = sorted(sentence_lengths)[len(sentence_lengths) // 2]\n",
    "\n",
    "# Plot the distribution of sentence lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sentence_lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.axvline(mean_length, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.axvline(median_length, color='green', linestyle='dashed', linewidth=2, label='Median')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Sentence Lengths')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the descriptive statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(f\"Minimum Sentence Length: {min_length}\")\n",
    "print(f\"Maximum Sentence Length: {max_length}\")\n",
    "print(f\"Mean Sentence Length: {mean_length:.2f}\")\n",
    "print(f\"Median Sentence Length: {median_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Word Frequency Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of tokens\n",
    "all_tokens = [token for tokens in transcriptions_tokens for token in tokens]\n",
    "\n",
    "# Count word frequency\n",
    "word_frequency = Counter(all_tokens)\n",
    "\n",
    "# Print the word frequency analysis\n",
    "print(\"Word Frequency:\")\n",
    "plt.plot(word_frequency.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique words in each sentence\n",
    "sentences = train_df['sentence'].tolist()\n",
    "unique_word_counts = [len(set(sentence.split())) for sentence in sentences]\n",
    "\n",
    "# Compute descriptive statistics\n",
    "min_unique_words = min(unique_word_counts)\n",
    "max_unique_words = max(unique_word_counts)\n",
    "mean_unique_words = sum(unique_word_counts) / len(unique_word_counts)\n",
    "median_unique_words = sorted(unique_word_counts)[len(unique_word_counts) // 2]\n",
    "\n",
    "# Plot the distribution of unique word counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(unique_word_counts, bins=50, color='lightcoral', edgecolor='black')\n",
    "plt.axvline(mean_unique_words, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.axvline(median_unique_words, color='green', linestyle='dashed', linewidth=2, label='Median')\n",
    "plt.xlabel('Number of Unique Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Unique Words in Transcriptions')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the descriptive statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(f\"Minimum Number of Unique Words: {min_unique_words}\")\n",
    "print(f\"Maximum Number of Unique Words: {max_unique_words}\")\n",
    "print(f\"Mean Number of Unique Words: {mean_unique_words:.2f}\")\n",
    "print(f\"Median Number of Unique Words: {median_unique_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 1000 sentences \n",
    "sentences = train_df['sentence'][:10000].tolist()\n",
    "\n",
    "# Tokenization using NLTK\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer\n",
    "sentences_tokens = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "\n",
    "# Remove Bengali stopwords\n",
    "sentences_no_stopwords = [\n",
    "    [word for word in tokens if word not in stop_words]\n",
    "    for tokens in sentences_tokens\n",
    "]\n",
    "\n",
    "# Convert tokenized sentences back to strings\n",
    "sentences_processed = [' '.join(tokens) for tokens in sentences_no_stopwords]\n",
    "\n",
    "# Create a CountVectorizer to convert text data to a bag-of-words representation\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(sentences_processed)\n",
    "\n",
    "# Perform LDA topic modeling\n",
    "n_topics = 10  # Number of topics to discover\n",
    "lda_model = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda_model.fit(X)\n",
    "\n",
    "# Get the top words for each topic\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "top_words_per_topic = []\n",
    "for topic_idx, topic in enumerate(lda_model.components_):\n",
    "    top_words = [feature_names[i] for i in topic.argsort()[:-4:-1]]\n",
    "    top_words_per_topic.append(top_words)\n",
    "\n",
    "# Print the top words for each topic\n",
    "for i, top_words in enumerate(top_words_per_topic):\n",
    "    print(f\"Topic {i + 1}: {' '.join(top_words)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Domain Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in np.arange(5):\n",
    "    audio_file_path = f'{domains}/{DOMAINS[idx]}'\n",
    "\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    # Print DOMAIN\n",
    "    print(DOMAINS[idx])\n",
    "    ipd.display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of domains and their corresponding audio files\n",
    "DOMAINS = [\n",
    "    'Audiobook.wav', 'Parliament Session.wav', 'Bangladeshi TV Drama.wav',\n",
    "    'Poem Recital.wav', 'Bengali Advertisement.wav', 'Puthi Literature.wav',\n",
    "    'Cartoon.wav', 'Slang Profanity.mp3', 'Debate.wav', 'Stage Drama Jatra.wav',\n",
    "    'Indian TV Drama.wav', 'Talk Show Interview.wav', 'Movie.wav', 'Telemedicine.mp3',\n",
    "    'News Presentation.wav', 'Waz Islamic Sermon.wav', 'Online Class.wav'\n",
    "]\n",
    "\n",
    "# Visualize the audio files and play them\n",
    "for idx in np.arange(5):\n",
    "    audio_file_path = os.path.join(domains, DOMAINS[idx])\n",
    "\n",
    "    # Load the audio file using librosa\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "\n",
    "    # Plot the waveform using the basic matplotlib plot function\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(np.linspace(0, len(audio) / sr, num=len(audio)), audio)\n",
    "    plt.title(f'Waveform - {DOMAINS[idx]}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot the spectrogram\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='linear')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Spectrogram - {DOMAINS[idx]}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.show()\n",
    "\n",
    "    # Play the audio\n",
    "    print(f\"Audio: {DOMAINS[idx]}\")\n",
    "    ipd.display(ipd.Audio(audio, rate=sr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **External Package Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define your package directory\n",
    "# package_dir = \"E:\\\\Studies\\\\11th Semester\\\\425\\\\Project\\\\Dataset\\\\python packages\"\n",
    "\n",
    "# # Install jiwer\n",
    "# !pip install \"{package_dir}\\\\jiwer\\\\jiwer-2.3.0-py3-none-any.whl\"\n",
    "\n",
    "# # Install bnunicodenormalizer\n",
    "# !pip install \"{package_dir}\\\\normalizer\\\\bnunicodenormalizer-0.0.24.tar.gz\"\n",
    "\n",
    "# # Install pyctcdecode\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\attrs-22.1.0-py2.py3-none-any.whl\"\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\exceptiongroup-1.0.0rc9-py3-none-any.whl\"\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\hypothesis-6.54.4-py3-none-any.whl\"\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\"\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\pygtrie-2.5.0.tar.gz\"\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\sortedcontainers-2.4.0-py2.py3-none-any.whl\"\n",
    "# !pip install \"{package_dir}\\\\pyctcdecode\\\\pyctcdecode-0.4.0-py2.py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanji\\anaconda3\\envs\\425\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import typing as tp  # Typing module for type hints\n",
    "from pathlib import Path  # For working with file paths\n",
    "from functools import partial  # To create partial functions\n",
    "from dataclasses import dataclass, field  # For creating data classes\n",
    "\n",
    "import pandas as pd \n",
    "import pyctcdecode  # For CTC decoding\n",
    "import numpy as np  \n",
    "from tqdm.notebook import tqdm  # For creating progress bars\n",
    "\n",
    "import librosa  # For audio processing\n",
    "\n",
    "import pyctcdecode  # For CTC decoding\n",
    "import kenlm  # For working with KenLM language model\n",
    "import torch  # PyTorch library for machine learning\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ProcessorWithLM, Wav2Vec2ForCTC  # For loading and processing Wav2Vec2 models\n",
    "from bnunicodenormalizer import Normalizer  # For Bengali Unicode normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting Paths and Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define paths and parameters for the project\n",
    "DATA = Path(r\"E:\\\\Studies\\\\11th Semester\\\\425\\\\Project\\\\Dataset\\\\bengaliai-speech\")\n",
    "TRAIN = DATA / \"train_mp3s\"\n",
    "TEST = DATA / \"test_mp3s\"\n",
    "SAMPLING_RATE = 16_000\n",
    "MODEL_PATH = Path(r\"E:\\Studies\\\\11th Semester\\\\425\\Project\\\\Dataset\\\\Wav2Vec2\\\\indicwav2vec_v1_bengali\")\n",
    "LM_PATH = Path(r\"E:\\Studies\\\\11th Semeste\\\\425\\\\Project\\\\Dataset\\\\Wav2Vec2\\\\wav2vec2-xls-r-300m-bengali\\\\language_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loading Speech Recognition Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Wav2Vec2 model and processor\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_PATH)  # CTC instance\n",
    "# processor will be responsible for handling the audion data\n",
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the vocabulary and a decoder\n",
    "\n",
    "# Get the vocabulary from the model's tokenizer\n",
    "vocab_dict = processor.tokenizer.get_vocab()\n",
    "print('lENGTH OF THE VOCABULARY: ',len(vocab_dict))\n",
    "vocab_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Building Vocabulary and CTC Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Sort the vocabulary based on token IDs\n",
    "sorted_vocab_dict = {k: v for k, v in sorted(vocab_dict.items(), key=lambda item: item[1])}\n",
    "\n",
    "# Define the language model path\n",
    "LM_PATH = Path(r\"E:\\Studies\\11th Semester\\425\\Project\\Dataset\\Wav2Vec2\\wav2vec2-xls-r-300m-bengali\\language_model\")\n",
    "\n",
    "# Build a CTC decoder using the sorted vocabulary and a language model\n",
    "decoder = pyctcdecode.build_ctcdecoder(\n",
    "    list(sorted_vocab_dict.keys()),  # Vocabulary keys\n",
    "    str(LM_PATH / \"5gram.bin\"),  # Path to the language model file\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating Combined Processor for Model Input and Decoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined processor for Wav2Vec2 model input and language model decoding\n",
    "processor_with_lm = Wav2Vec2ProcessorWithLM(\n",
    "    feature_extractor=processor.feature_extractor,  # Feature extractor for audio data\n",
    "    tokenizer=processor.tokenizer,  # Tokenizer for text data\n",
    "    decoder=decoder  # Decoder for converting model output to text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Defining a Custom Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class BengaliSRTestDataset(Dataset):\n",
    "    # A custom dataset class for handling Bengali speech test data\n",
    "    \n",
    "    def __init__(self, audio_paths: list[str], sampling_rate: int):\n",
    "        # Constructor to initialize the dataset\n",
    "        \n",
    "        # Store the list of audio file paths\n",
    "        self.audio_paths = audio_paths\n",
    "        \n",
    "        # Store the sampling rate used for audio processing\n",
    "        self.sampling_rate = sampling_rate\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.audio_paths)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        # Get a sample from the dataset given an index\n",
    "        \n",
    "        # Get the audio file path corresponding to the index\n",
    "        audio_path = self.audio_paths[index]\n",
    "        \n",
    "        # Get the sampling rate from the dataset settings\n",
    "        sr = self.sampling_rate\n",
    "        \n",
    "        # Load the audio file using librosa, specifying the desired sampling rate\n",
    "        # 'mono=False' indicates to load the audio as a multi-channel signal\n",
    "        # [0] at the end gets the audio signal (the first element of the returned tuple)\n",
    "        audio_signal = librosa.load(audio_path, sr=sr, mono=False)[0]\n",
    "        \n",
    "        # Return the loaded audio signal as the sample\n",
    "        return audio_signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creating Test Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id                                           sentence\n",
      "0  0f3dac00655e  এছাড়াও নিউজিল্যান্ড এ ক্রিকেট দলের হয়েও খেলছ...\n",
      "1  a9395e01ad21  এছাড়াও নিউজিল্যান্ড এ ক্রিকেট দলের হয়েও খেলছ...\n",
      "2  bf36ea8b718d  এছাড়াও নিউজিল্যান্ড এ ক্রিকেট দলের হয়েও খেলছ...\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(DATA / \"sample_submission.csv\", dtype={\"id\": str})\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio_paths = [str(TEST / f\"{aid}.mp3\") for aid in test[\"id\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for testing using the list of test audio paths and specified sampling rate\n",
    "test_dataset = BengaliSRTestDataset(\n",
    "    test_audio_paths, SAMPLING_RATE\n",
    ")\n",
    "\n",
    "# Define a partial function for collating samples into batches\n",
    "collate_func = partial(\n",
    "    processor_with_lm.feature_extractor,\n",
    "    return_tensors=\"pt\", sampling_rate=SAMPLING_RATE,\n",
    "    padding=True,\n",
    ")\n",
    "\n",
    "# Create a data loader for testing\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=4, shuffle=False,\n",
    "    num_workers=0, collate_fn=collate_func, drop_last=False,\n",
    "    pin_memory=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting Up the Model for Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\")\n",
    "print(device)\n",
    "\n",
    "# attach cpu or gpu\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "model = model.half()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Performing Model Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pred_sentence_list = []  # Initialize an empty list to store predicted sentences\n",
    "\n",
    "# Perform inference without gradient computation because we are not fine tuning so we don't want to change the weights\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):  # Iterate through batches of test data\n",
    "        x = batch[\"input_values\"]  # Extract the input audio features from the batch\n",
    "        x = x.to(device, non_blocking=True)  # Move the input data to the device (GPU)\n",
    "        \n",
    "        # Use automatic mixed precision for faster and more memory-efficient inference\n",
    "        with torch.cuda.amp.autocast(True):\n",
    "            y = model(x).logits  # Get the model's output logits\n",
    "        del x\n",
    "        y = y.detach().cpu().numpy()  # Move the logits to the CPU and convert to a numpy array\n",
    "        \n",
    "        for l in y:  # Iterate through the logits of the batch\n",
    "            # Decode the logits into a sentence using the LM with beam search decoding\n",
    "            sentence = processor_with_lm.decode(l, beam_width=64).text\n",
    "            pred_sentence_list.append(sentence)  # Append the predicted sentence to the list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Postprocessing Predicted Sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnorm = Normalizer()  # Create a Normalizer object for text normalization\n",
    "\n",
    "def postprocess(sentence):\n",
    "    # Define a postprocessing function to clean up and format predicted sentences\n",
    "    \n",
    "    period_set = set([\".\", \"?\", \"!\", \"।\"])  # Set of sentence-ending punctuation\n",
    "    \n",
    "    # Split the sentence into words and apply normalization using the Normalizer\n",
    "    _words = [bnorm(word)['normalized'] for word in sentence.split() if word]\n",
    "    \n",
    "    sentence = \" \".join(_words)\n",
    "    \n",
    "    if not sentence.endswith(tuple(period_set)):\n",
    "        sentence += \"।\"\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 460.68it/s]\n"
     ]
    }
   ],
   "source": [
    "pp_pred_sentence_list = [\n",
    "    postprocess(s) for s in tqdm(pred_sentence_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording...\n",
      "Recording finished\n",
      "Recognized Text: আমি আমি যদি কথা বলি এখানে আসবে\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(duration=5, fs=16000):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording finished\")\n",
    "    return recording.flatten()\n",
    "\n",
    "# Function to make predictions from audio\n",
    "def recognize_speech(model, processor, audio, device):\n",
    "    # Preprocess the audio to model's expected format\n",
    "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    input_values = input_values.to(device)\n",
    "\n",
    "    # Convert input_values to the same dtype as model (half precision)\n",
    "    input_values = input_values.half()\n",
    "\n",
    "    # Perform inference with the model\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Ensure logits are two-dimensional (time, vocabulary)\n",
    "    if len(logits.shape) == 1:\n",
    "        logits = logits.unsqueeze(0)\n",
    "\n",
    "    # Convert logits to numpy array\n",
    "    logits = logits.cpu().numpy()\n",
    "\n",
    "    # Decode the logits to text using the processor's decode method\n",
    "    # Extract only the 'text' attribute from the output\n",
    "    transcription = processor.decode(logits[0]).text\n",
    "    return transcription\n",
    "\n",
    "\n",
    "# Record audio from microphone\n",
    "audio_data = record_audio(duration=5)\n",
    "\n",
    "# Recognize speech\n",
    "transcription = recognize_speech(model, processor_with_lm, audio_data, device)\n",
    "print(\"Recognized Text:\", transcription)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <span style=\"font-size:50px;\"><b>Understanding and Responding</b></span>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clearing GPU Cache**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Loading and Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(\"E:/Studies/11th Semester/425/Project/train.csv\")\n",
    "\n",
    "# Preprocess\n",
    "df['text'] = df['context'] + \"\\n\" + df['reply']\n",
    "df['text'].to_csv(\"E:/Studies/11th Semester/425/Project/train.txt\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting Up Language Model for Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"D:\\\\fall 23\\\\cse425\\\\425 project\\\\gpt2-bengali\"\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=f\"{local_model_path}/tokenizer.json\")\n",
    "model = GPT2LMHeadModel.from_pretrained(local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"E:\\\\Studies\\\\11th Semester\\\\425\\\\Project\\\\train.txt\",\n",
    "    block_size=128\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=False)\n",
    "    for batch in progress_bar:\n",
    "        inputs = batch[0].to(device)  # batch is a list with a single tensor\n",
    "        labels = inputs\n",
    "\n",
    "        outputs = model(inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the progress bar with the loss value\n",
    "        progress_bar.set_postfix({'loss': loss.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Saving the Fine-Tuned Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./gpt2-bengali-finetuned-final\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting Up an Interactive Voice Bot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "from normalizer import normalize\n",
    "import logging\n",
    "from transformers import logging as hf_logging\n",
    "import warnings\n",
    "# from transformers import LogitsProcessorList, MinLengthLogitsProcessor, RepetitionPenaltyLogitsProcessor\n",
    "\n",
    "# Suppress warnings from sounddevice\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# Suppress certain warnings from transformers\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "# Suppress other warnings (like those from loading models)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(duration=5, fs=16000):\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording finished\")\n",
    "    return recording.flatten()\n",
    "\n",
    "# Function to recognize speech using Wav2Vec2\n",
    "def recognize_speech(model, processor, audio, device):\n",
    "    input_values = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
    "    input_values = input_values.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    if len(logits.shape) == 1:\n",
    "        logits = logits.unsqueeze(0)\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.decode(predicted_ids[0], skip_special_tokens=True)\n",
    "    return transcription\n",
    "\n",
    "# Function to generate a response\n",
    "def generate_response(input_text, model, tokenizer, device):\n",
    "    if not input_text.strip():  # Check for empty string\n",
    "        return \"No input provided.\"\n",
    "\n",
    "    # Ensure \"।\" is in the tokenizer's vocabulary\n",
    "    if \"।\" not in tokenizer.get_vocab():\n",
    "        tokenizer.add_special_tokens({'additional_special_tokens': [\"।\"]})\n",
    "        model.resize_token_embeddings(len(tokenizer))  # Resize model embeddings to fit the new token\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True)\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "    # Set \"।\" as the eos_token_id for generation\n",
    "    eos_token_id = tokenizer.convert_tokens_to_ids(\"।\")\n",
    "\n",
    "    # Decoding settings\n",
    "    generation_parameters = {\n",
    "    \"max_length\": 128,  # Sets the maximum length of the sequence to be generated. Limits how long the response can be.\n",
    "    \"temperature\": 0.7,  # Controls the randomness of predictions by scaling the logits before applying softmax. Lower values make the model more confident in its top choices, while higher values increase randomness.\n",
    "    \"num_beams\": 3,  # Number of beams to use in beam search. Beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set. More beams increase the chances of finding a more accurate prediction but at the cost of more computation.\n",
    "    \"no_repeat_ngram_size\": 2,  # Ensures that no n-gram (in this case, a 2-gram) appears more than once. Helps prevent repetitive text.\n",
    "    \"early_stopping\": True,  # If True, generation is stopped as soon as all beam candidates have reached the EOS token. This can speed up generation but might result in shorter outputs.\n",
    "    \"attention_mask\": attention_mask,  # The attention mask that was applied to the inputs. It makes sure that the model only attends to relevant portions of the input sequence.\n",
    "    \"eos_token_id\": eos_token_id,  # Specifies the token that represents the end of a sentence, helping the model understand where to stop generating further text.\n",
    "    \"num_return_sequences\": 1,  # The number of sequences to return. Here, it's set to 1, meaning the model will return the best sequence it finds.\n",
    "}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(input_ids, **generation_parameters)\n",
    "\n",
    "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # Find the first occurrence of \"।\" and cut off the rest\n",
    "    end_idx = response.find(\"।\")\n",
    "    if end_idx != -1:\n",
    "        response = response[:end_idx + 1]\n",
    "\n",
    "    # Remove any unwanted characters\n",
    "    response = response.replace(\"?\", \"\").strip()\n",
    "\n",
    "    # Remove any part of the response that repeats the input\n",
    "    if input_text in response:\n",
    "        response = response.replace(input_text, '').strip()\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# Load the Wav2Vec2 model and processor\n",
    "wav2vec2_model_path = r\"E:\\\\Studies\\\\11th Semester\\\\425\\\\Project\\\\Dataset\\\\Wav2Vec2\\\\indicwav2vec_v1_bengali\"\n",
    "wav2vec2_model = Wav2Vec2ForCTC.from_pretrained(wav2vec2_model_path)\n",
    "wav2vec2_processor = Wav2Vec2Processor.from_pretrained(wav2vec2_model_path)\n",
    "\n",
    "# Load your fine-tuned GPT-2 Bengali model\n",
    "gpt2_model_path = \"E:\\\\Studies\\\\11th Semester\\\\425\\\\Project\\\\gpt2-bengali-finetuned-final\"\n",
    "gpt2_tokenizer = PreTrainedTokenizerFast(tokenizer_file=f\"{gpt2_model_path}/tokenizer.json\")\n",
    "\n",
    "\n",
    "# Set padding token to EOS token\n",
    "# If your tokenizer does not have an EOS token, you'll need to add a new special token for padding\n",
    "if gpt2_tokenizer.eos_token is None:\n",
    "    gpt2_tokenizer.add_special_tokens({'eos_token': '[EOS]'})\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "\n",
    "# Ensure the model's config pad token id is set\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(gpt2_model_path)\n",
    "gpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "wav2vec2_model.to(device)\n",
    "gpt2_model.to(device)\n",
    "\n",
    "# Start the conversation loop\n",
    "print(\"The Voice Bot is ready to talk! Press Ctrl+C to end the conversation.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        audio_data = record_audio(duration=5)\n",
    "        if audio_data is not None and audio_data.size > 0:\n",
    "            transcription = recognize_speech(wav2vec2_model, wav2vec2_processor, audio_data, device)\n",
    "            print(f\"You: {transcription}\")\n",
    "            response = generate_response(transcription, gpt2_model, gpt2_tokenizer, device)\n",
    "            print(f\"Bot: {response}\")\n",
    "        else:\n",
    "            print(\"No audio detected.\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nConversation ended.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
